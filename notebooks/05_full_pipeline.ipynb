{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUCmVEV4gYaW"
      },
      "outputs": [],
      "source": [
        "# HIGGS Dataset – Logistic Regression vs Neural Network (Full Pipeline)\n",
        "\n",
        "This notebook runs the full experiment:\n",
        "\n",
        "1. Load the HIGGS dataset\n",
        "2. Preprocess data (check missing values, duplicates, scaling)\n",
        "3. Train Logistic Regression across multiple training sample sizes\n",
        "4. Train Neural Network (MLPClassifier) across the same sample sizes\n",
        "5. Generate:\n",
        "   - Performance vs sample size plots\n",
        "   - Training time vs sample size plots\n",
        "   - ROC and PR curves for both models\n",
        "   - Comparison plots (F1 + Training Time)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    roc_auc_score,\n",
        "    average_precision_score,\n",
        "    roc_curve,\n",
        "    precision_recall_curve\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "DATA_PATH = r\"C:\\MSAI\\Machine Learning\\Assignment 3\\HIGGS.csv\"\n",
        "OUTPUT_DIR = r\"C:\\MSAI\\Machine Learning\\Assignment 3\"\n",
        "\n",
        "PERCENTAGES = [1, 2, 3, 4, 5, 10, 15, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "print(\"Data path:\", DATA_PATH)\n",
        "print(\"Output dir:\", OUTPUT_DIR)\n"
      ],
      "metadata": {
        "id": "PaX83UN7gbe0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_classifier(clf, X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Fits model on training data, predicts on test data,\n",
        "    and returns metrics + training time.\n",
        "    \"\"\"\n",
        "    import time\n",
        "    start_time = time.time()\n",
        "    clf.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "\n",
        "    y_pred = clf.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"train_time\": train_time\n",
        "    }\n"
      ],
      "metadata": {
        "id": "KhUDxT0xgeQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 1. Load and Explore Data\n"
      ],
      "metadata": {
        "id": "H6Tc_1glggfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(DATA_PATH, header=None)\n",
        "print(\"Dataset loaded successfully!\")\n",
        "print(\"Shape:\", df.shape)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "5luXW5mhghE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "missing_counts = df.isnull().sum()\n",
        "print(\"Total missing values:\", missing_counts.sum())\n",
        "\n",
        "# Duplicates\n",
        "duplicate_count = df.duplicated().sum()\n",
        "print(\"Number of duplicated rows:\", duplicate_count)\n",
        "\n",
        "# Class balance\n",
        "print(\"\\nClass distribution (counts):\")\n",
        "print(df[0].value_counts())\n",
        "\n",
        "print(\"\\nClass distribution (proportions):\")\n",
        "print(df[0].value_counts(normalize=True))\n"
      ],
      "metadata": {
        "id": "uCYmjrz_gisJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary = df.describe().T\n",
        "summary_path = os.path.join(OUTPUT_DIR, \"higgs_summary.txt\")\n",
        "with open(summary_path, \"w\") as f:\n",
        "    f.write(summary.to_string())\n",
        "\n",
        "print(\"Summary file saved at:\", summary_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "aWwJZQivgldf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 2. Train–Test Split and Scaling\n"
      ],
      "metadata": {
        "id": "4udXTF1ygot6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df[0]          # target\n",
        "X = df.iloc[:, 1:] # 28 features\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, Y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=Y\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", X_train.shape)\n",
        "print(\"Test set shape:\", X_test.shape)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "print(\"Scaling complete!\")\n",
        "print(\"Scaled train shape:\", X_train_scaled.shape)\n",
        "print(\"Scaled test shape:\", X_test_scaled.shape)\n",
        "\n",
        "n_train = X_train_scaled.shape[0]\n"
      ],
      "metadata": {
        "id": "_r7fwicwgrjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 3. Logistic Regression – Experiments Across Sample Sizes\n"
      ],
      "metadata": {
        "id": "5hDjsvBPgtzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_lr = []\n",
        "\n",
        "for p in PERCENTAGES:\n",
        "    frac = p / 100.0\n",
        "    n_samples = int(n_train * frac)\n",
        "\n",
        "    X_sub = X_train_scaled[:n_samples]\n",
        "    y_sub = y_train.iloc[:n_samples]\n",
        "\n",
        "    print(f\"[LR] Training with {p}% of training data ({n_samples} samples)\")\n",
        "\n",
        "    lr_clf = LogisticRegression(\n",
        "        max_iter=1000,\n",
        "        solver=\"saga\",\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    metrics = evaluate_classifier(lr_clf, X_sub, y_sub, X_test_scaled, y_test)\n",
        "    metrics[\"percentage\"] = p\n",
        "    metrics[\"n_samples\"] = n_samples\n",
        "\n",
        "    results_lr.append(metrics)\n",
        "\n",
        "results_lr_df = pd.DataFrame(results_lr)\n",
        "results_lr_df\n"
      ],
      "metadata": {
        "id": "jtU9lj3KgvUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_report_path = os.path.join(OUTPUT_DIR, \"LogisticRegressionReport.txt\")\n",
        "with open(lr_report_path, \"w\") as f:\n",
        "    f.write(results_lr_df.to_string())\n",
        "\n",
        "print(\"Logistic Regression report saved at:\", lr_report_path)\n"
      ],
      "metadata": {
        "id": "ZZU8UnCGgw8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"accuracy\"], marker=\"o\", label=\"Accuracy\")\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"precision\"], marker=\"o\", label=\"Precision\")\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"recall\"], marker=\"o\", label=\"Recall\")\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"f1\"], marker=\"o\", label=\"F1-score\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Logistic Regression Performance vs Sample Size (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "LLaKpimogyvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"train_time\"], marker=\"o\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"Training Time (seconds)\")\n",
        "plt.title(\"Logistic Regression Training Time vs Sample Size (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uncvtRDbg0Vy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_full = LogisticRegression(\n",
        "    max_iter=1000,\n",
        "    solver=\"saga\",\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "lr_full.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_score_lr = lr_full.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ROC\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, y_score_lr)\n",
        "roc_auc_lr = roc_auc_score(y_test, y_score_lr)\n",
        "\n",
        "# PRC\n",
        "prec_lr, rec_lr, _ = precision_recall_curve(y_test, y_score_lr)\n",
        "ap_lr = average_precision_score(y_test, y_score_lr)\n",
        "\n",
        "print(f\"LR ROC AUC: {roc_auc_lr:.4f}\")\n",
        "print(f\"LR AP (PR AUC): {ap_lr:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f\"LR (AUC = {roc_auc_lr:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – Logistic Regression on HIGGS\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(rec_lr, prec_lr, label=f\"LR (AP = {ap_lr:.3f})\")\n",
        "baseline = y_test.mean()\n",
        "plt.hlines(baseline, 0, 1, colors='k', linestyles='--',\n",
        "           label=f\"Baseline (pos rate = {baseline:.2f})\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curve – Logistic Regression on HIGGS\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zy_Y2B9hg2LE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 4. Neural Network (MLP) – Experiments Across Sample Sizes\n"
      ],
      "metadata": {
        "id": "IhxsYwPlg6uS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_nn = []\n",
        "\n",
        "for p in PERCENTAGES:\n",
        "    frac = p / 100.0\n",
        "    n_samples = int(n_train * frac)\n",
        "\n",
        "    X_sub = X_train_scaled[:n_samples]\n",
        "    y_sub = y_train.iloc[:n_samples]\n",
        "\n",
        "    print(f\"[NN] Training with {p}% of training data ({n_samples} samples)\")\n",
        "\n",
        "    nn_clf = MLPClassifier(\n",
        "        hidden_layer_sizes=(128, 64),\n",
        "        activation=\"relu\",\n",
        "        solver=\"adam\",\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    metrics = evaluate_classifier(nn_clf, X_sub, y_sub, X_test_scaled, y_test)\n",
        "    metrics[\"percentage\"] = p\n",
        "    metrics[\"n_samples\"] = n_samples\n",
        "\n",
        "    results_nn.append(metrics)\n",
        "\n",
        "results_nn_df = pd.DataFrame(results_nn)\n",
        "results_nn_df\n"
      ],
      "metadata": {
        "id": "0fLebjCjg8N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn_report_path = os.path.join(OUTPUT_DIR, \"NeuralNetworkReport.txt\")\n",
        "with open(nn_report_path, \"w\") as f:\n",
        "    f.write(results_nn_df.to_string())\n",
        "\n",
        "print(\"Neural Network report saved at:\", nn_report_path)\n"
      ],
      "metadata": {
        "id": "UWOTLDprg8sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"accuracy\"], marker=\"o\", label=\"Accuracy\")\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"precision\"], marker=\"o\", label=\"Precision\")\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"recall\"], marker=\"o\", label=\"Recall\")\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"f1\"], marker=\"o\", label=\"F1-score\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"Score\")\n",
        "plt.title(\"Neural Network Performance vs Sample Size (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qUKcx9cNg_J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"train_time\"], marker=\"o\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"Training Time (seconds)\")\n",
        "plt.title(\"Neural Network Training Time vs Sample Size (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pBFbKQTshBAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training full Neural Network model on all training data for ROC/PR curves...\")\n",
        "nn_full = MLPClassifier(\n",
        "    hidden_layer_sizes=(128, 64),\n",
        "    activation=\"relu\",\n",
        "    solver=\"adam\",\n",
        "    max_iter=1000,\n",
        "    random_state=42\n",
        ")\n",
        "nn_full.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_score_nn = nn_full.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# ROC\n",
        "fpr_nn, tpr_nn, _ = roc_curve(y_test, y_score_nn)\n",
        "roc_auc_nn = roc_auc_score(y_test, y_score_nn)\n",
        "\n",
        "# PRC\n",
        "prec_nn, rec_nn, _ = precision_recall_curve(y_test, y_score_nn)\n",
        "ap_nn = average_precision_score(y_test, y_score_nn)\n",
        "\n",
        "print(f\"NN ROC AUC: {roc_auc_nn:.4f}\")\n",
        "print(f\"NN AP (PR AUC): {ap_nn:.4f}\")\n",
        "\n",
        "# Combined ROC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f\"LR (AUC = {roc_auc_lr:.3f})\")\n",
        "plt.plot(fpr_nn, tpr_nn, label=f\"NN (AUC = {roc_auc_nn:.3f})\")\n",
        "plt.plot([0, 1], [0, 1], 'k--', label=\"Random\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve – HIGGS (Logistic Regression vs Neural Network)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Combined PRC\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(rec_lr, prec_lr, label=f\"LR (AP = {ap_lr:.3f})\")\n",
        "plt.plot(rec_nn, prec_nn, label=f\"NN (AP = {ap_nn:.3f})\")\n",
        "baseline = y_test.mean()\n",
        "plt.hlines(baseline, 0, 1, colors='k', linestyles='--',\n",
        "           label=f\"Baseline (pos rate = {baseline:.2f})\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision–Recall Curve – HIGGS (Logistic Regression vs Neural Network)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7jS-hYNIhCdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 5. LR vs NN – F1 and Training Time Comparison\n"
      ],
      "metadata": {
        "id": "686weqMIhFaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"f1\"], marker=\"o\", label=\"LR F1\")\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"f1\"], marker=\"o\", label=\"NN F1\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"F1-score\")\n",
        "plt.title(\"F1-score vs Training Size – LR vs NN (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o_UCQw5KhFz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(results_lr_df[\"percentage\"], results_lr_df[\"train_time\"], marker=\"o\", label=\"LR Train Time\")\n",
        "plt.plot(results_nn_df[\"percentage\"], results_nn_df[\"train_time\"], marker=\"o\", label=\"NN Train Time\")\n",
        "plt.xlabel(\"Training Data Used (%)\")\n",
        "plt.ylabel(\"Training Time (seconds)\")\n",
        "plt.title(\"Training Time vs Training Size – LR vs NN (HIGGS)\")\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "A79BTcQghIe_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}